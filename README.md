# AI-Powered Sign Language Recognition System

## üìñ Overview
This project is an **AI-powered sign language recognition system** designed to enhance accessibility and communication for individuals with hearing or speech impairments.  
By combining **computer vision** and **deep learning**, the system captures hand gestures through a webcam and translates them into text in real time.  

The goal of this project is to demonstrate how AI can be applied to build inclusive solutions that bridge communication gaps.

---

## ‚ú® Features
- Real-time hand gesture detection using **OpenCV**
- **Convolutional Neural Network (CNN)** trained to classify sign gestures
- Live video input from webcam
- Instant translation of gestures into text
- Simple interface for real-time feedback
- Dataset can be extended to support more gestures

---

## üõ†Ô∏è Tech Stack
- **Programming Language**: Python  
- **Frameworks**: TensorFlow, Keras  
- **Libraries**: OpenCV, NumPy, Pandas, Matplotlib  
- **Dataset**: Custom/preprocessed images of sign gestures  
- **Model**: CNN classifier trained on labeled gesture dataset  

---

## üöÄ Setup Instructions
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/sign-language-recognition.git
   cd sign-language-recognition



---
---
## üì∏ Demo Screenshots

Below are examples of the system detecting and recognizing hand gestures in real time:

### 1. Recognizing Number "5"
![Hand showing 5 fingers](screenshots/5.png)

### 2. Recognizing Letter "E" (Live Detection)
![Hand showing letter E detected](screenshots/e.png)

### 3. Reference ‚Äî ASL Letter "E"
![Reference ASL letter E](screenshots/OIP.webp)
---
